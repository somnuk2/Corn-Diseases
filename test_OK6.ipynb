{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF9uvbXNVrVY"
      },
      "source": [
        "## Import TensorFlow and other libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFBhRrrEI49z"
      },
      "source": [
        "It's good practice to use a validation split when developing your model. Let's use 80% of the images for training, and 20% for validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "#----------------------------------------------------------------------------------------------------------------\n",
        "batch_size = 7  # Load 7 images at a time\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "#----------------------------------------------------------------------------------------------------------------\n",
        "# Paths to your image files\n",
        "img_paths = [\n",
        "    \"D:/CNN-With/data/CDM/CDMls206 - Copy - Copy.jpg\",\n",
        "    \"D:/CNN-With/data/HT/ht206 - Copy - Copy.jpg\",\n",
        "    \"D:/CNN-With/data/MDMV/MDMVls1 - Copy (2).jpg\",\n",
        "    \"D:/CNN-With/data/NCLB/NCLBls1 - Copy (2).jpg\",\n",
        "    \"D:/CNN-With/data/SCLB/SCLBls1 - Copy.jpg\",\n",
        "    \"D:/CNN-With/data/SCMV/SCMVls1 - Copy.jpg\",\n",
        "    \"D:/CNN-With/data/SR/SRls1 - Copy - Copy.jpg\"\n",
        "]\n",
        "\n",
        "# Load and preprocess images\n",
        "images = []\n",
        "for img_path in img_paths:\n",
        "    img = image.load_img(img_path, target_size=(img_height, img_width))\n",
        "    img_array = image.img_to_array(img)  # Convert to numpy array\n",
        "    images.append(img_array)\n",
        "\n",
        "# Convert the list of images to a numpy array\n",
        "images = np.array(images)\n",
        "\n",
        "# Add batch dimension (batch_size, height, width, channels)\n",
        "# Images are already in the right shape (7, 224, 224, 3), no need to expand dimensions\n",
        "\n",
        "# Normalize the images (if the model requires it, adjust as needed)\n",
        "# images = images / 255.0  # Uncomment if model was trained with normalized images\n",
        "\n",
        "#----------------------------------------------------------------------------------------------------------------\n",
        "class_names = ['CDM', 'HT', 'MDMV', 'NCLB', 'SCLB', 'SCMV', 'SR']  # Class names for the images\n",
        "print(\"Class Names:\", class_names)\n",
        "#----------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# Define the path where the model is saved (in H5 format)\n",
        "saved_model_path = \"D:/CNN-With/Trained_Model_Cnn/model.h5\"\n",
        "\n",
        "# Load the model\n",
        "model = tf.keras.models.load_model(saved_model_path)\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n",
        "#----------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# Predict using the loaded model\n",
        "predictions = model.predict(images)\n",
        "\n",
        "# If the model has logits as output, apply softmax\n",
        "if 'from_logits' in model.loss.get_config() and model.loss.get_config()['from_logits']:\n",
        "    predictions = tf.nn.softmax(predictions).numpy()\n",
        "\n",
        "# Create a DataFrame to show the prediction probabilities for all images\n",
        "pred_df = pd.DataFrame(predictions, columns=class_names)\n",
        "\n",
        "# Display the prediction results for all images\n",
        "print(\"Prediction results for the images:\")\n",
        "print(pred_df)\n",
        "\n",
        "# Assuming true labels for the images (replace with actual labels)\n",
        "true_labels = [\"CDM\", \"HT\", \"MDMV\", \"NCLB\", \"SCLB\", \"SCMV\", \"SR\"]  # Replace with actual labels\n",
        "predicted_labels = pred_df.idxmax(axis=1).tolist()  # Get the predicted label for each image\n",
        "confidences = pred_df.max(axis=1).tolist()  # Get the confidence of each prediction\n",
        "\n",
        "# Print the true labels, predicted labels, and their respective confidence\n",
        "for i in range(batch_size):\n",
        "    print(f\"\\nImage {i+1}:\")\n",
        "    print(f\"True Label: {true_labels[i]}\")\n",
        "    print(f\"Predicted Label: {predicted_labels[i]}\")\n",
        "    print(f\"Prediction Confidence: {confidences[i]:.4f}\")\n",
        "\n",
        "#----------------------------------------------------------------------------------------------------------------\n",
        "# Create confusion matrix for the batch\n",
        "cm = confusion_matrix(true_labels, predicted_labels, labels=class_names)\n",
        "\n",
        "# Convert confusion matrix to DataFrame for better readability\n",
        "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "\n",
        "# Print the confusion matrix\n",
        "print(\"Confusion Matrix for the batch:\\n\")\n",
        "print(cm_df)\n",
        "\n",
        "# Calculate Precision, Recall, and F1-Score for the batch\n",
        "precision = precision_score(true_labels, predicted_labels, average=None, labels=class_names)\n",
        "recall = recall_score(true_labels, predicted_labels, average=None, labels=class_names)\n",
        "f1 = f1_score(true_labels, predicted_labels, average=None, labels=class_names)\n",
        "\n",
        "# Display metrics\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Precision': precision,\n",
        "    'Recall': recall,\n",
        "    'F1-Score': f1\n",
        "}, index=class_names)\n",
        "\n",
        "print(\"\\nPrecision, Recall, and F1-Score for each class:\")\n",
        "print(metrics_df)\n",
        "\n",
        "# Optionally, calculate average precision, recall, and F1-Score for the batch\n",
        "average_precision = precision_score(true_labels, predicted_labels, average='macro')\n",
        "average_recall = recall_score(true_labels, predicted_labels, average='macro')\n",
        "average_f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
        "\n",
        "print(f\"\\nAverage Precision: {average_precision:.4f}\")\n",
        "print(f\"Average Recall: {average_recall:.4f}\")\n",
        "print(f\"Average F1-Score: {average_f1:.4f}\")\n",
        "\n",
        "#----------------------------------------------------------------------------------------------------------------\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title('Confusion Matrix for the Batch of Images')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.show()\n",
        "\n",
        "# Plotting the metrics table as a heatmap (similar to confusion matrix)\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.heatmap(metrics_df, annot=True, fmt='.4f', cmap='Blues', cbar=False, annot_kws={\"size\": 12},\n",
        "            xticklabels=metrics_df.columns, yticklabels=metrics_df.index, linewidths=1, linecolor='black')\n",
        "plt.title(\"Precision, Recall, and F1-Score for each Class\")\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Classes')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "deep",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
